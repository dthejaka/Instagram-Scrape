{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wilpaththuwa - Done\n",
    "Hortonplains - Done\n",
    "Minneriya - Done upto 2019 Jan 07\n",
    "Udawalawa\n",
    "Bundala - done upto 2019 feb ithink\n",
    "Kaudulla - done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\win_unicode_console\\__init__.py:31: RuntimeWarning: sys.stdin.encoding == 'utf-8', whereas sys.stdout.encoding == 'UTF-8', readline hook consumer may assume they are the same\n",
      "  readline_hook.enable(use_pyreadline=use_pyreadline)\n"
     ]
    }
   ],
   "source": [
    "import instaloader\n",
    "from instaloader import Instaloader,  Profile\n",
    "import datetime\n",
    "from itertools import dropwhile, takewhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = Instaloader(download_comments=False, download_pictures=True,download_videos=False, download_geotags=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded session from D:\\UNI STUFF\\Stat\\4th year\\Research\\Instaloader\\session-dheedith.\n"
     ]
    }
   ],
   "source": [
    "import instaloader\n",
    "\n",
    "# Get instance\n",
    "#L = instaloader.Instaloader()\n",
    "\n",
    "\n",
    "USER = 'dheedith'\n",
    "#PASSWORD = 'research123'\n",
    "# Optionally, login or load session\n",
    "# L.login(USER, PASSWORD)        # (login)\n",
    "# L.interactive_login(USER)      # (ask password on terminal)\n",
    "L.load_session_from_file(USER, filename=r'D:\\UNI STUFF\\Stat\\4th year\\Research\\Instaloader\\session-dheedith') # (load session created w/\n",
    "                               #  `instaloader -l USERNAME`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hortonplainsnationalpark\\2019-10-04_01-48-07_UTC.jpg exists [#hortonplainsnationalpark #srâ€¦] unchanged json \n",
      "hortonplainsnationalpark\\2019-10-04_01-46-38_UTC.jpg [#hortonplainsnationalpark #srâ€¦] json \n",
      "hortonplainsnationalpark\\2019-10-04_01-44-49_UTC.jpg [#hortonplainsnationalpark #srâ€¦] json \n",
      "hortonplainsnationalpark\\2019-12-01_15-20-52_UTC_1.jpg "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "HASHTAG = 'hortonplainsnationalpark'\n",
    "post_iterator = L.get_hashtag_posts(HASHTAG)\n",
    "\n",
    "\n",
    "try:\n",
    "    for post in post_iterator:\n",
    "        date = post.date_utc\n",
    "        if date.year <= 2019:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "except:\n",
    "    iteratorfreeze = post_iterator.freeze()\n",
    "    with open(f'{HASHTAG}2.pkl', 'wb') as resumefile:\n",
    "        pickle.dump(iteratorfreeze, resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hortonplainsnationalpark\\2018-12-16_17-13-33_UTC.jpg [View from Hakgala botanical gâ€¦] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JSON Query to explore/locations/225187162/: Expecting value: line 1 column 1 (char 0) [retrying; skip with ^C]\n",
      "JSON Query to explore/locations/225187162/: Expecting value: line 1 column 1 (char 0) [retrying; skip with ^C]\n"
     ]
    }
   ],
   "source": [
    "#load\n",
    "import pickle\n",
    "HASHTAG = 'hortonplainsnationalpark'\n",
    "post_iterator = L.get_hashtag_posts(HASHTAG)\n",
    "with open(f'{HASHTAG}2.pkl', 'rb') as resumefile:\n",
    "    resumeint = pickle.load(resumefile)\n",
    "    post_iterator.thaw(resumeint)\n",
    "\n",
    "try:\n",
    "    for post in post_iterator:\n",
    "        date = post.date_utc\n",
    "        if date.year <= 2018:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "except:\n",
    "    iteratorfreeze = post_iterator.freeze()\n",
    "    with open(f'{HASHTAG}2.pkl', 'wb') as resumefile:\n",
    "        pickle.dump(iteratorfreeze, resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wilpaththu\\2016-11-29_17-55-18_UTC.jpg exists [#nature#Wilpaththu#C.Haththotâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-24-27_UTC.jpg exists [#thilinaphotographyâ„¢#thirdeyeâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-23-27_UTC.jpg exists [#dancingbirds#wilpaththu#thilâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-22-22_UTC.jpg exists [#thilinaphotographyâ„¢#thirdeyeâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-21-16_UTC.jpg exists [#legend#pictureoftheyear#thilâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-19-44_UTC.jpg exists [#nornted#wilpaththu#thilinaphâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-18-42_UTC.jpg exists [#naturelove#thilinaphotographâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-17-45_UTC.jpg exists [#wilpaththu#thirdeye#thilinapâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-16-45_UTC.jpg exists [#thilinaphotographyâ„¢#natureloâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-15-43_UTC.jpg exists [#thilinaphotographyâ„¢#natureloâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-13-27_UTC.jpg exists [#happyfamily#wilpaththu#thirdâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-12-32_UTC.jpg exists [#thilinaphotography#thirdeye#â€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-11-44_UTC.jpg exists [#thilinaphotography#naturelovâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-09-28_UTC.jpg exists [#wilpaththu#naturelove#myhobbâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-08-33_UTC.jpg exists [#watcheye#thilinaphotography#â€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-07-18_UTC.jpg exists [#thirdeye#naturelove#myhobby#â€¦] unchanged json \n",
      "wilpaththu\\2016-11-24_14-06-17_UTC.jpg exists [#thilinaphotography#naturelovâ€¦] unchanged json \n",
      "wilpaththu\\2016-11-23_14-10-30_UTC.jpg [#leopard #cat #bigcat #jungleâ€¦] json \n",
      "wilpaththu\\2016-11-21_19-10-03_UTC.jpg [Try Capture the best shot..paâ€¦] geo json \n",
      "wilpaththu\\2016-11-21_12-45-13_UTC.jpg [Special Roti Burger @wilpathtâ€¦] geo json \n",
      "wilpaththu\\2016-11-21_11-18-25_UTC.jpg [white bellied sea eagle at wiâ€¦] json \n",
      "wilpaththu\\2016-11-20_03-37-17_UTC.jpg [\"I don't wanna talk to you\"  â€¦] json \n",
      "wilpaththu\\2016-11-12_17-22-51_UTC.jpg [#wilpaththu#wildlife#myhobby#â€¦] json \n",
      "wilpaththu\\2016-11-12_17-21-56_UTC.jpg [#thilinaphotography#myhobby#wâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-21-09_UTC.jpg [#thilinaphotography#wilpaththâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-20-07_UTC.jpg [#thilinaphotography#wildlife#â€¦] json \n",
      "wilpaththu\\2016-11-12_17-19-22_UTC.jpg [#thilinaphotography#myhobby#nâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-17-35_UTC.jpg [#thilinaphotography#wilpaththâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-16-37_UTC.jpg [#naturelove#myhobby#wilpaththâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-15-52_UTC.jpg [#naturelove#wilpaththu#thilinâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-13-56_UTC.jpg [#watcheye#thilinaphotography#â€¦] json \n",
      "wilpaththu\\2016-11-12_17-12-40_UTC.jpg [#wildlife#wilpaththu#natureloâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-11-34_UTC.jpg [#thilinaphotography#myhobby#wâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-10-07_UTC.jpg [#wildlife#wilpaththu#thilinapâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-08-56_UTC.jpg [#naturelove#wildlife#thilinapâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-04-29_UTC.jpg [#Rational click#wilpaththu#myâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-03-01_UTC.jpg [#thilinaphotography#wilpaththâ€¦] json \n",
      "wilpaththu\\2016-11-12_17-01-22_UTC.jpg [#thilinaphotography#naturelovâ€¦] json \n",
      "wilpaththu\\2016-11-09_14-45-39_UTC.jpg [#wilpaththu #trip #206#] json \n",
      "wilpaththu\\2016-11-08_01-37-01_UTC.jpg [#wilpaththu #] json \n",
      "wilpaththu\\2016-11-05_06-17-44_UTC.jpg [Leopard spotted at Willpaththâ€¦] json \n",
      "wilpaththu\\2016-11-02_01-52-04_UTC.jpg [#2016 #wilpaththu #egal #wilpâ€¦] json \n",
      "wilpaththu\\2016-10-26_01-47-14_UTC.jpg [#bird #wilpaththu #2016 #tripâ€¦] json \n",
      "wilpaththu\\2016-10-23_12-33-09_UTC.jpg [Nobody #owns the #world so feâ€¦] geo json \n",
      "wilpaththu\\2016-10-19_01-06-34_UTC.jpg [#wilpaththu #bird #2016 #] json \n",
      "wilpaththu\\2016-10-18_11-13-32_UTC.jpg [The leopard dubbed \"Y\" blocksâ€¦] json \n",
      "wilpaththu\\2016-10-17_10-09-22_UTC.jpg [Hide and seek champion.  #leoâ€¦] json \n",
      "wilpaththu\\2016-10-15_16-07-42_UTC.jpg [#wilpaththu #2016 #] json \n",
      "wilpaththu\\2016-10-15_02-58-58_UTC.jpg [Mr. \"Y\" the leopard , a very â€¦] geo json \n",
      "wilpaththu\\2016-10-14_16-51-23_UTC.jpg [An eagle-eye view across the â€¦] geo json \n",
      "wilpaththu\\2016-10-14_14-02-59_UTC.jpg [#wilpaththu #wilpattu_birds#] json \n",
      "wilpaththu\\2016-10-14_13-28-25_UTC.jpg [#wilpaththu # eagle #srilankaâ€¦] geo json \n",
      "wilpaththu\\2016-10-14_13-24-08_UTC.jpg [#wilpaththu #2016 #srilanka #] json \n",
      "wilpaththu\\2016-10-14_12-07-57_UTC.jpg [When leopard goes derp. #leopâ€¦] json \n",
      "wilpaththu\\2016-10-14_11-35-16_UTC.jpg [evening function in maradanmaâ€¦] geo json \n",
      "wilpaththu\\2016-10-13_01-44-36_UTC.jpg [traveling to wilpaththu #travâ€¦] geo json \n",
      "wilpaththu\\2016-10-11_02-29-30_UTC.jpg [The big cat called \"Y\" spotteâ€¦] geo json \n",
      "wilpaththu\\2016-10-09_13-29-42_UTC.jpg [\"Plans to protect air and watâ€¦] geo json \n",
      "wilpaththu\\2016-10-05_13-44-42_UTC.jpg [#wilpaththu #wildlife #natureâ€¦] geo json \n",
      "wilpaththu\\2016-10-05_06-21-35_UTC.jpg [#srilanka #wilpaththu #wildliâ€¦] geo json \n",
      "wilpaththu\\2016-10-04_08-50-02_UTC.jpg [#light #camping #wilpaththu] geo json \n",
      "wilpaththu\\2016-10-03_13-15-39_UTC.jpg [The dance of the the peacock.â€¦] json \n",
      "wilpaththu\\2016-09-28_04-00-26_UTC.jpg [#32Â°C#wilpaththu#à¶šà·œà¶±à·Šà¶©à¶‹à¶šà·”à·ƒà·Šà·ƒà·] geo json \n",
      "wilpaththu\\2016-09-26_10-56-34_UTC.jpg [#paintings #offroading #wilpaâ€¦] json \n",
      "wilpaththu\\2016-09-24_13-41-25_UTC.jpg [#Holy #offroading  #wilpaththâ€¦] json \n",
      "wilpaththu\\2016-09-18_12-57-16_UTC.jpg [Forget yourself once in a whiâ€¦] geo json \n",
      "wilpaththu\\2016-09-18_01-29-42_UTC.jpg [Annual trip'16 ðŸ›£ðŸŒ³ðŸ˜Ž #waytogoboâ€¦] geo json \n",
      "wilpaththu\\2016-09-18_01-22-59_UTC.jpg [Off for a nice outing... Way â€¦] json \n",
      "wilpaththu\\2016-09-17_09-05-47_UTC.jpg [My last leopard encounter at â€¦] json \n",
      "wilpaththu\\2016-09-16_14-39-46_UTC.jpg [Peacock's dust bath. #peacockâ€¦] json \n",
      "wilpaththu\\2016-09-15_11-20-55_UTC.jpg [The most chilled Purple facedâ€¦] json \n",
      "wilpaththu\\2016-09-02_16-39-02_UTC.jpg [#naturelove#thirdeye#wilpathtâ€¦] json \n",
      "wilpaththu\\2016-09-02_16-37-23_UTC.jpg [#thirdeye#naturelove#thilinapâ€¦] json \n",
      "wilpaththu\\2016-09-01_14-17-41_UTC.jpg [Sri Lankan Jungle fowl , natiâ€¦] json \n",
      "wilpaththu\\2016-08-30_12-24-08_UTC.jpg [#canon #wilpaththu #crested #â€¦] geo json \n",
      "wilpaththu\\2016-08-18_13-05-30_UTC.jpg [Foliage of Willpaththu... #wiâ€¦] json \n",
      "wilpaththu\\2016-08-15_13-04-17_UTC.jpg [Mugger crocodile at Willpathtâ€¦] json \n",
      "wilpaththu\\2016-08-06_07-22-26_UTC.jpg [The road block... #leopard #wâ€¦] json \n",
      "wilpaththu\\2016-08-04_05-30-37_UTC.jpg [Once discovered, you must #Exâ€¦] json \n",
      "wilpaththu\\2016-08-03_19-07-11_UTC.jpg [There's a #monkey in this picâ€¦] json \n",
      "wilpaththu\\2016-06-24_03-26-51_UTC.jpg [Some of the #camping sites inâ€¦] json \n",
      "wilpaththu\\2016-06-18_05-36-41_UTC.jpg [A Kingfisher with its breakfaâ€¦] json \n",
      "wilpaththu\\2016-06-14_07-56-06_UTC.jpg [In #wilpaththu national park â€¦] json \n",
      "wilpaththu\\2016-06-08_10-24-56_UTC.jpg [Sunset at panikkawila #wilpatâ€¦] json \n",
      "wilpaththu\\2016-06-05_20-11-15_UTC.jpg [Wilpathu National Park, Sri Lâ€¦] json \n",
      "wilpaththu\\2016-06-05_19-36-37_UTC.jpg [Wilpathu National Park, Sri Lâ€¦] json \n",
      "wilpaththu\\2016-06-04_02-30-16_UTC.jpg [At #Wilpaththu] json \n",
      "wilpaththu\\2016-05-31_06-22-05_UTC.jpg [#wilpaththu #fun #trip #family] json \n",
      "wilpaththu\\2016-05-05_07-30-49_UTC.jpg [A close encounter by @dannydoâ€¦] json \n",
      "wilpaththu\\2016-05-02_21-58-23_UTC.jpg [Tiger family in Yala Nationalâ€¦] geo json \n",
      "wilpaththu\\2016-04-27_02-52-29_UTC.jpg [why pretend when you can be yâ€¦] json \n",
      "wilpaththu\\2016-04-24_18-13-55_UTC.jpg [Explore the Wilpaththu Nationâ€¦] json \n",
      "wilpaththu\\2016-04-22_10-30-24_UTC.jpg [#Wilpaththu #Safari #Badiudeeâ€¦] json \n",
      "wilpaththu\\2016-03-27_05-22-13_UTC.jpg [#pantheraPardusKotiya #SriLanâ€¦] json \n",
      "wilpaththu\\2016-03-27_05-17-57_UTC.jpg [#pantheraPardusKotiya #SriLanâ€¦] json \n",
      "wilpaththu\\2016-03-10_14-32-11_UTC.jpg [#srilanka #sunset #wilpaththuâ€¦] json \n",
      "wilpaththu\\2016-02-22_13-01-08_UTC.jpg [Out of the woods.. I crawl.. â€¦] json \n",
      "wilpaththu\\2016-01-14_16-35-51_UTC.jpg [#deer #wildlife #wildwilpattuâ€¦] geo json \n",
      "wilpaththu\\2016-01-14_14-10-26_UTC.jpg [Hello moon says The Sun #sunsâ€¦] geo json \n",
      "wilpaththu\\2016-01-14_13-09-09_UTC.jpg [#eagles #sl #srilanka #wilpatâ€¦] json \n",
      "wilpaththu\\2016-01-12_02-18-15_UTC.jpg [#peacock #bluepeacock #birdloâ€¦] geo json \n",
      "wilpaththu\\2016-01-07_14-16-47_UTC.jpg [#peacock #bluepeacock #natureâ€¦] geo json \n",
      "wilpaththu\\2016-01-06_17-47-02_UTC.jpg [#myway #myworld #saseemalpallâ€¦] geo json \n",
      "wilpaththu\\2016-01-05_16-21-35_UTC.jpg [à¶…à·„à·’à¶‚à·ƒà¶šà¶­à·Šà·€à¶º... #srilanka #wilpâ€¦] geo json \n",
      "wilpaththu\\2016-01-05_06-07-49_UTC.jpg [#wilpaththu #srilanka #wild #â€¦] geo json \n",
      "wilpaththu\\2016-01-04_16-13-10_UTC.jpg [#peacock #bluepeacock #wildwiâ€¦] geo json \n",
      "wilpaththu\\2016-01-02_13-06-59_UTC.jpg [#elegance #beauty #nature #naâ€¦] geo json \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "HASHTAG = 'hortonplainsnationalpark'\n",
    "post_iterator = L.get_hashtag_posts(HASHTAG)\n",
    "\n",
    "\n",
    "try:\n",
    "    for post in post_iterator:\n",
    "        date = post.date_utc\n",
    "        if date.year == 2018:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "except:\n",
    "    iteratorfreeze = post_iterator.freeze()\n",
    "    with open(f'{HASHTAG}3.pkl', 'wb') as resumefile:\n",
    "        pickle.dump(iteratorfreeze, resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "HASHTAG = 'wilpaththu'\n",
    "post_iterator = L.get_hashtag_posts(HASHTAG)\n",
    "\n",
    "\n",
    "try:\n",
    "    for post in post_iterator:\n",
    "        date = post.date_utc\n",
    "        if date.year == 2015:\n",
    "            if date.month < 2:\n",
    "                L.download_post(post, target=HASHTAG)\n",
    "except:\n",
    "    iteratorfreeze = post_iterator.freeze()\n",
    "    with open(f'{HASHTAG}4.pkl', 'wb') as resumefile:\n",
    "        pickle.dump(iteratorfreeze, resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "import pickle\n",
    "HASHTAG = 'wilpaththu'\n",
    "post_iterator = L.get_hashtag_posts(HASHTAG)\n",
    "with open(f'{HASHTAG}3.pkl', 'rb') as resumefile:\n",
    "    resumeint = pickle.load(resumefile)\n",
    "    post_iterator.thaw(resumeint)\n",
    "\n",
    "try:\n",
    "    for post in post_iterator:\n",
    "        date = post.date_utc\n",
    "        if date.year == 2016:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "\n",
    "except:\n",
    "    iteratorfreeze = post_iterator.freeze()\n",
    "    with open(f'{HASHTAG}3.pkl', 'wb') as resumefile:\n",
    "        pickle.dump(iteratorfreeze, resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wilpaththu\\2014-12-22_11-28-21_UTC.jpg [Helping a random guy who got â€¦] json \n",
      "wilpaththu\\2014-12-06_14-23-41_UTC.jpg [#wilpaththu #*.* #wildlife #sâ€¦] geo json \n",
      "wilpaththu\\2014-11-30_10-27-32_UTC.jpg [#hyperlapse#safari#wilpaththu] json \n",
      "wilpaththu\\2014-09-28_17-18-38_UTC.jpg [#leopard ðŸ¯ðŸ† â¤ï¸ #beautiful #srâ€¦] json \n",
      "wilpaththu\\2014-08-02_08-35-21_UTC.jpg [#wildlife#safari#wilpaththu] geo json \n",
      "wilpaththu\\2014-07-18_14-09-37_UTC.jpg [#Birding #WildlifePhotographyâ€¦] json \n",
      "wilpaththu\\2014-06-24_07-19-35_UTC.jpg [ðŸ˜ #park #srilanka #trip to #mâ€¦] json \n",
      "wilpaththu\\2014-05-16_14-44-13_UTC.jpg [Safaris are fun even when allâ€¦] json \n",
      "wilpaththu\\2013-06-09_17-47-59_UTC.jpg [#trip #fun #wilpaththu #awsome] json \n",
      "wilpaththu\\2013-06-09_17-40-27_UTC.jpg [#trip #safari #jungle #fun #fâ€¦] json \n",
      "wilpaththu\\2012-09-21_03-03-22_UTC.jpg [#Wilpaththu #sky] json \n",
      "wilpaththu\\2012-09-21_03-00-49_UTC.jpg [#Wilpaththu #Spotteddear #wilâ€¦] json \n",
      "wilpaththu\\2012-09-21_02-58-48_UTC.jpg [#Wilpaththu #Spotteddear#wildâ€¦] json \n",
      "wilpaththu\\2012-09-21_02-55-11_UTC.jpg [#Wilpaththu #Fox] json \n",
      "wilpaththu\\2012-09-21_02-52-47_UTC.jpg [#Wilpaththu#forest#Jungle#] json \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "HASHTAG = 'wilpaththu'\n",
    "post_iterator = L.get_hashtag_posts(HASHTAG)\n",
    "\n",
    "\n",
    "try:\n",
    "    for post in post_iterator:\n",
    "        date = post.date_utc\n",
    "        if date.year == 2014:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "        elif date.year == 2013:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "        elif date.year == 2012:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "        elif date.year == 2011:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "        elif date.year == 2010:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "except:\n",
    "    iteratorfreeze = post_iterator.freeze()\n",
    "    with open(f'{HASHTAG}5.pkl', 'wb') as resumefile:\n",
    "        pickle.dump(iteratorfreeze, resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wilpaththu5.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-baf23502a240>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mHASHTAG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'wilpaththu'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpost_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_hashtag_posts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHASHTAG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{HASHTAG}5.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresumefile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mresumeint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresumefile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpost_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthaw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresumeint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wilpaththu5.pkl'"
     ]
    }
   ],
   "source": [
    "#load\n",
    "import pickle\n",
    "HASHTAG = 'wilpaththu'\n",
    "post_iterator = L.get_hashtag_posts(HASHTAG)\n",
    "with open(f'{HASHTAG}5.pkl', 'rb') as resumefile:\n",
    "    resumeint = pickle.load(resumefile)\n",
    "    post_iterator.thaw(resumeint)\n",
    "\n",
    "try:\n",
    "    for post in post_iterator:\n",
    "        date = post.date_utc\n",
    "        if date.year == 2014:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "        elif date.year == 2013:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "        elif date.year == 2012:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "        elif date.year == 2011:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "        elif date.year == 2010:\n",
    "            L.download_post(post, target=HASHTAG)\n",
    "\n",
    "except:\n",
    "    iteratorfreeze = post_iterator.freeze()\n",
    "    with open(f'{HASHTAG}5.pkl', 'wb') as resumefile:\n",
    "        pickle.dump(iteratorfreeze, resumefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from where we left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded session from D:\\UNI STUFF\\Stat\\4th year\\Research\\Instaloader\\session-research_scrape123new.\n"
     ]
    }
   ],
   "source": [
    "import instaloader\n",
    "from instaloader import Instaloader,  Profile\n",
    "import datetime\n",
    "from itertools import dropwhile, takewhile\n",
    "\n",
    "L = Instaloader(download_comments=False, download_pictures=True, download_geotags=True,download_videos=False, )\n",
    "\n",
    "import instaloader\n",
    "\n",
    "# Get instance\n",
    "#L = instaloader.Instaloader()\n",
    "\n",
    "\n",
    "USER = 'research_scrape123'\n",
    "#PASSWORD = 'research1'\n",
    "# Optionally, login or load session\n",
    "#L.login(USER, PASSWORD)        # (login)\n",
    "#L.interactive_login(USER)      # (ask password on terminal)\n",
    "L.load_session_from_file(USER, filename=r'D:\\UNI STUFF\\Stat\\4th year\\Research\\Instaloader\\session-research_scrape123new') # (load session created w/\n",
    "                               #  `instaloader -l USERNAME`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wilpaththu\\2019-04-07_03-16-05_UTC.jpg exists [#randomclick #iphonography #eâ€¦] unchanged "
     ]
    }
   ],
   "source": [
    "#load\n",
    "import pickle\n",
    "HASHTAG = 'wilpaththu'\n",
    "post_iterator = L.get_hashtag_posts(HASHTAG)\n",
    "with open(f'{HASHTAG}.pkl', 'rb') as resumefile:\n",
    "    resumeint = pickle.load(resumefile)\n",
    "    post_iterator.thaw(resumeint)\n",
    "\n",
    "try:\n",
    "    for post in post_iterator:\n",
    "        L.download_post(post, target=HASHTAG)\n",
    "            #count += 1\n",
    "\n",
    "except:\n",
    "    iteratorfreeze = post_iterator.freeze()\n",
    "    with open(f'{HASHTAG}.pkl', 'wb') as resumefile:\n",
    "        pickle.dump(iteratorfreeze, resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1274"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_iterator.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path = r'D:\\UNI STUFF\\Stat\\4th year\\Research\\Instaloader\\wilpaththu'\n",
    "photos = glob.glob(path + \"/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
